{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload reloads modules automatically before before executing user code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter's trick\n",
    "- Tab: Compelete  \n",
    "- Shift + Tab Parameter: Quick inspect the parameters  \n",
    "- Shift + Tab X2 or X3: More information  \n",
    "- ??function: Get soure code  \n",
    "- ?function: Get documentation\n",
    "- Running a bash command in a Jupyter notebook using !\n",
    "    - !ls {PATH} Python variables must be inside the {}\n",
    "    - !ls -lh: Get size of a file\n",
    "    - !wc -l file_name: Get number of rows of a csv file\n",
    "- %prun: Show execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "- Pandas works really well with numpy: We can apply a numpy function on a Pandas Series. Ex: df.SalePrice = np.log(df.SalePrice)\n",
    "- Remove a column from DataFrame: df.drop(column_name, axis = 1)\n",
    "- Useful read_csv parameters\n",
    "```python\n",
    "pd.read_csv(f'{PATH}Train.csv', low_memory=False, parse_dates=[\"saledate\"])\n",
    "# low_memory=False : parse all dtypes of the file\n",
    "# parse_dates=[] : give all columns that are with dtype data (and will convert them to DataTime dtype)\n",
    "```\n",
    "- A good practice is to save/load DataFrame by using feather so we can access it efficiently:\n",
    "```python\n",
    "os.makedirs('tmp', exist_ok=True)  # Create a folder\n",
    "df.to_feather('tmp/raw')  # Save\n",
    "df = pd.read_feather('tmp/raw')  # Load\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "- If the dataset contain a mix of continuous and categorical variables, convert everything into numbers.\n",
    "- Always do feature extraction step when working with __date-time__, so we can capture any trend/cyclical behavior like holiday, weekend, sport event, rainning that day, etc. df.saledate.__dt.__\n",
    "- Always do as much of our works as we can on a small sample of the data.\n",
    "- Remove outliers which make sense and there is no other variable to capture those outlier. For example: If the store has extra sale data before and after closing period, and we donâ€™t have any data to model the outliers then we should remove them during training.\n",
    "- If we don't have a good validation set, it's impossible to create a good model.\n",
    "- Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorems, Lingos, Terms\n",
    "_Curse of dimensionality_: The more columns we have, the more empty space it creates. KNN works very well in high dimensions despite what the theory said because the points still have different distances away from each other.\n",
    "\n",
    "_No free lunch theorem_: In theory, there is no model that works well for any kind of dataset. In practice, we can use random forest for nearly all kind of dataset.\n",
    "\n",
    "_Churn_: Loss of users\n",
    "\n",
    "_Viral coefficient_: the ability of a business to tap into an early user base and get that user base to tell other people about it. If a site has a viral coefficient of 10%, and has 1,000 users, then after one month it will gain another 100 users through viral channels.\n",
    "\n",
    "_Ground truth_: Ground truth refers to strong labels that have a high likelihood of being accurate, knowledge that we're very sure is True.\n",
    "\n",
    "_Correlation does not imply causation!_: Just because we can see a connection or a mutual relationship between two variables, it doesn't mean that one causes the other.\n",
    "\n",
    "_Cardinality_: The number of levels in a category (Sex has a cardinality of 2, zipcode has a cardinality of 5000)\n",
    "\n",
    "_Entropy_: Measure of impurity - P(a) x log(P(a)) - P(b) x log(P(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate success and iterate\n",
    "- Cross validation and testing\n",
    "- Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips when doing projects\n",
    "- Build a Random Forest as fast as we can, try to get into the point that it's significan better than random.\n",
    "- Find feature important by randoming shuffle 1 feature, run through the same model, make prediction, then compare to previous RMSE. Plot the future important (Dendrogram)\n",
    "- Talk to client about the important features, what does that mean, where does it come from. They might disagree with important feature from our plots. Thus client might miss-understanding of the data they gave us and we have a __data leakage__ problem (There is information in the data set that we were modeling with which client wouldn't have had in real life at the point when they were making a decision) \n",
    "- Start throwing out unimportant features away.\n",
    "- Create a new Random Forest to see if our score doesn't change much.\n",
    "- Removing redundant features by using a dendrogram (hierarchical clustering).\n",
    "- Partial dependence: A powerful technique to find out for the features that are important, how do they realate to the dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "- Overfitting is when the model performs very well on traing data but poorly on unseen test data. It \"overfits\" to the training data, usually indicating it has too much complexity in regards to the training data size.\n",
    "- Fix: Increase the training data, regularization, early stopping, K-Fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy VS Precision VS Recall\n",
    "- __Accuracy__: Ratio of correct predicted observation to the total observations. Only useful measure where values of FP and FN are the same. Accurary = (TP+TN) / (TP+FP+FN+TN)\n",
    "- __Precision__: Ratio of correct predicted positive observation to the toal predicted positive. Precision = TP / (TP+FP)\n",
    "- __Recall__: Ratio of correct predicted positive observation to all observations in the actual class. Recall = TP / (TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "- Metrics to evaluate a regression task: \n",
    "    - Root Mean Squared Error (RMSE)\n",
    "    - Mean Squared Error (MSE)\n",
    "    - Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes algorithm\n",
    "- It __assumes__ (may not always true) that the features X are conditionally independent of each other for the given y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype a Machine Learning Algorithm\n",
    "_Regression_: Predict continous variables  \n",
    "_Classify_: Predict categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "- A linear regression models the relationship between the dependent variable y and the independent variable x.\n",
    "- Main assumptions:\n",
    "    - The relationship between y and x is linear\n",
    "    - The residual errors from the regression fit are normally distributed\n",
    "- _Common estimation techniques for linear regression_: \n",
    "    - Ordinary Least Squares\n",
    "    - Generalized Least Square\n",
    "    - Penalized Least Squares (L1 and L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Pass the linear regression model into the logistic function. Output < 0.5 is 0 and output > 0.5 is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "- Build a Decision Tree from scratch:\n",
    "    - Calculate the root mean squared error of the 1st split. This number would represents how good a split is.\n",
    "    - Try all variables and all possible value of that variable and see which variable and which value gives us a split with the best score.\n",
    "    - Stop splitting when the leaf node only has 1 thing in it.\n",
    "- Advantages:\n",
    "    - Very easy to inteprest and understand\n",
    "    - Work on both continous and categorical variables\n",
    "    - No normalization or scaling need\n",
    "    - Prediction algorithm runs very fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Tree algorihm VS Random Forest algorithm\n",
    "- __Boosting Tree algorithm__: \n",
    "    - Run the Boosting Trees 1 time. Assign heavier weight to points that were hard to classify, then reiterate.\n",
    "    - Boosting Tree is a iterative algorithm where each execution is based on the previous result.\n",
    "- __Random Forest algorithm__: Instead of using information gain to calculate the root node, the process of fidning the root node and splitting the features nodes will happen randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Random Forest: constructs a multiple of decision trees at training time and output the class labels (Classification) or mean prediction (Regression) of the individual trees. \n",
    "- Random Forest is kind of universal ML algo works with any kind of data. It's not overfit, doesn't assume our data is normally distributed, doesn't assume the relationship is linear, require a little of feature engineering. \n",
    "- Random Forest (Predict on uncorrelated trees):  \n",
    "    - Grab some rows as random then put them into a smaller dataset and build a tree based on that\n",
    "    - Do it again with a different random subset\n",
    "    - Make prediction on each tree\n",
    "    - Take an average  \n",
    "- Use Out-of-bag (OOB) error to prevent over fitting or for small dataset: Pass un-used rows to the 1st tree and treat it as a validation set. Do the same thing for a 2nd tree. To calculation prediction, we would average all the trees where that row is not used for training\n",
    "- Confidence of tree level: We calculate the standard deviation for each row that we got from the random forest model, then we group them according to difference variables or predictors to see which particular prediction has high standard deviation.\n",
    "- Tree interpreter: Doing feature important for a particular observation. Ex: Which feature will impact a patient to readmit to the hospital and how can we change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2483c1d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate data\n",
    "X = np.linspace(0,1)\n",
    "y = X + np.random.uniform(-0.2,0.2,X.shape)\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 1D to 2D array\n",
    "X = X[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "X_train, X_test = X[:40], X[40:]\n",
    "y_train, y_test = y[:40], y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=1,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=1, max_depth=1, bootstrap=False)\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a23b2ea58>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the result\n",
    "plt.scatter(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can fix this by using a Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce over-overfitting\n",
    "- Subsampling: The easiest way to avoid over-fitting is also the best way to speed up analysis. Rather then limit the total amount of data our model can access, we just limit it to a _different_ random subset per tree. Given enough trees, the model can still see _all_ the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "- Attempt to find the hyperplane that seperate classes by maximizing the space between the 2 classes.\n",
    "- SVM can use __kernel trick__ to map non-separable linear inputs into a higher dimension where they become more easily to seperate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
