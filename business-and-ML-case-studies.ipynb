{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to measure TV Marketing performance: \n",
    "- Gross Rating point. Goal is to get the cost per point as low as possible.\n",
    "- Number of calls using a special number for TV only\n",
    "- Track used special coupon codes for TV only\n",
    "- Website visits and conversions (Search traffic immediately following the TV ad)\n",
    "- App downloads immediately following the TV ad\n",
    "- Use credit card purchase data to see how TV ads influence purchase behavior.\n",
    "- Control/Test scenario: Wayfair runs TV advertising in Boston but not in Chicago. Boston and Chicago are very similar demographics, market share, competitors activity, etc. Any change in Boston could be associated with the TV ad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the performance of a new Facebook Messenger app? What metrics would you use?\n",
    "- Check before and after _Daily Active User (ADU)_ and _Monthly Active User (MAU)_ metric to compare if users have moved on to the new app.\n",
    "- Track _Total Time Spent_ to compare engagement before and after\n",
    "- Number of messages being sent before and after channge.\n",
    "- Response time to messages received.\n",
    "- Increased metrics can sometimnes be deceiving: More time being spent on the app because it is harder to use? Could this affect advertising revenue changes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find out if people like the new button feature (A/B Testing)\n",
    "- Decie on metrics to compare between the 2 version: Daily Active User, Monthly Active User, Click Through Rate, Engagement, Total Time Spent, etc.\n",
    "- Prepare 2 version of the site. 1 without the change, another version with the new feature change.\n",
    "- Serve differen versions of the pages to the populations. Randomly split the population (Be careful not to introduce biases when randomly splitting)\n",
    "- Create a null hypothesis testing (Daily Active User will be the same for both groups)\n",
    "- For the hypothesis test you will pre-define the acceptable Type I Error (FPR or alpha)\n",
    "- Using this you can use the p-value to decive if the results are significant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can you know if a sample is biased? \n",
    "- Take multiple sub-samples.\n",
    "- Check if these sub-samples Mean are normally distribited around the true mean (Bootstrapping)\n",
    "### Different type of bias:\n",
    "- Selection bias: Sampling everage weight of the US by only sampling IL.\n",
    "- Measurement bias: Sampling from a stream of information, but your sampling rate is lower than the actual rate of change on the stream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Deep Learning at Scale in Twitterâ€™s Timelines\n",
    "- In order to predict if a tweet would be engaging to you, Twitter consider these features:\n",
    "    - The Tweet itself: its recency, medias, number of retweets or likes.\n",
    "    - The Tweet's author: Your past interactions with the authors, strength of our connection.\n",
    "    - You: Tweets you like in the past, how often you use Twitte    \n",
    "- Challenge: quality and speed of predictions at instant time, resource utilization, maintainability.\n",
    "- Track: Number os engagements per user, total time user spend on Twitter\n",
    "- Before launching model: need to know the impact of the model and weigh that against any increase in the cost of running the model (Higher hardware utilization, more complicated operation and support). A more complicated model which can only extended by only a few engineers is a bad long-term bet, even if it has a slight edge in performance.\n",
    "- Add 2 extra custom sparse linear layer:\n",
    "    - Online normalization scheme that prevents gradients from exploding.\n",
    "    - Per-feature bias to distinguish between the absense of a feature and the presence of a zero-valued feature.\n",
    "- How to deal with low latencies: Use the right mix of batching, multithreading, and hardware utilization\n",
    "- Better design of the platform:\n",
    "    - Easy training and reuse of the models: simple flow and model reference makes it easy to reproduce sequence tasks or assemble models.\n",
    "    - Automatic bundling for optimal interection with cluster resources.\n",
    "    - Testing and serving: After model is trained, it needs to be able to run large-scale experiments on it. This requires extensive testing of the model in PROD env.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
